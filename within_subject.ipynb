{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import seaborn as sns\n",
    "import nolds\n",
    "from scipy import stats\n",
    "from scipy.signal import welch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import QuantileTransformer, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_RATE = 256\n",
    "SEED = 42\n",
    "labels_folder = \"D:/Repos/reading_comprehension_EEG/our_data/labels\"\n",
    "data_folder = \"D:/Repos/reading_comprehension_EEG/our_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "subjects = ['lea','finn','sarah', 'aurora', 'bjoern', 'derek', 'dimi', 'ronan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_nested_numpy(lst):\n",
    "    if isinstance(lst, list):\n",
    "        return np.array([list_to_nested_numpy(item) for item in lst])\n",
    "    else:\n",
    "        return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lea\n",
      "finn\n",
      "sarah\n",
      "aurora\n",
      "bjoern\n",
      "derek\n",
      "dimi\n",
      "ronan\n"
     ]
    }
   ],
   "source": [
    "subj_data = {}\n",
    "for subj in subjects:\n",
    "    print(subj)\n",
    "    df = pd.read_csv(labels_folder+\"/events_\" + subj + \".txt\", delim_whitespace=True)\n",
    "    df = df[(df.number != \"condition\")]\n",
    "    subj_data[subj] = {}\n",
    "    subj_data[subj][\"labels\"] = df[\"number\"].to_numpy().astype(float)\n",
    "    subj_data[subj][\"timestamps\"] = df[\"type\"].to_numpy().astype(float)\n",
    "    if subj == 'aurora': # aurora is another format\n",
    "        df = pd.read_csv(data_folder+\"/\" + subj + \"_pre_processed_data.txt\", delim_whitespace=True)\n",
    "    else:\n",
    "        df = pd.read_csv(data_folder+\"/\" + subj + \"_pre_processed_data.txt\", delim_whitespace=False)\n",
    "    subj_data[subj][\"data\"] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111. 112. 100.\n",
      " 101. 102. 103. 195. 195. 106. 195. 108. 195. 110. 111. 100. 101. 102.\n",
      " 103. 104. 105. 195. 107.]\n"
     ]
    }
   ],
   "source": [
    "print(subj_data['aurora']['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in subjects:\n",
    "    if subj_data[x]['labels'][0] != 100 or subj_data[x]['labels'][1] == 100:\n",
    "        raise Exception(\"Something wrong with labels for \" + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>FP1</th>\n",
       "      <th>AF7</th>\n",
       "      <th>AF3</th>\n",
       "      <th>F1</th>\n",
       "      <th>F3</th>\n",
       "      <th>F5</th>\n",
       "      <th>F7</th>\n",
       "      <th>FT7</th>\n",
       "      <th>FC5</th>\n",
       "      <th>...</th>\n",
       "      <th>CP4</th>\n",
       "      <th>CP2</th>\n",
       "      <th>P2</th>\n",
       "      <th>P4</th>\n",
       "      <th>P6</th>\n",
       "      <th>P8</th>\n",
       "      <th>P10</th>\n",
       "      <th>PO8</th>\n",
       "      <th>PO4</th>\n",
       "      <th>O2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>39.0625</td>\n",
       "      <td>31.4110</td>\n",
       "      <td>32.0673</td>\n",
       "      <td>22.3352</td>\n",
       "      <td>25.0382</td>\n",
       "      <td>23.5137</td>\n",
       "      <td>35.1120</td>\n",
       "      <td>29.3931</td>\n",
       "      <td>22.0631</td>\n",
       "      <td>23.7075</td>\n",
       "      <td>...</td>\n",
       "      <td>27.3832</td>\n",
       "      <td>24.2128</td>\n",
       "      <td>19.9883</td>\n",
       "      <td>21.8572</td>\n",
       "      <td>40.9739</td>\n",
       "      <td>33.9711</td>\n",
       "      <td>26.3451</td>\n",
       "      <td>25.9169</td>\n",
       "      <td>24.9449</td>\n",
       "      <td>27.6925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>42.9688</td>\n",
       "      <td>33.7772</td>\n",
       "      <td>34.1328</td>\n",
       "      <td>24.6102</td>\n",
       "      <td>27.0248</td>\n",
       "      <td>24.8361</td>\n",
       "      <td>35.6534</td>\n",
       "      <td>32.2594</td>\n",
       "      <td>22.5779</td>\n",
       "      <td>25.0118</td>\n",
       "      <td>...</td>\n",
       "      <td>28.8048</td>\n",
       "      <td>25.0436</td>\n",
       "      <td>20.5898</td>\n",
       "      <td>23.3805</td>\n",
       "      <td>42.6280</td>\n",
       "      <td>35.6002</td>\n",
       "      <td>28.7708</td>\n",
       "      <td>30.2720</td>\n",
       "      <td>26.4836</td>\n",
       "      <td>29.2275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>46.8750</td>\n",
       "      <td>43.6999</td>\n",
       "      <td>42.6404</td>\n",
       "      <td>34.5724</td>\n",
       "      <td>36.4731</td>\n",
       "      <td>33.9406</td>\n",
       "      <td>42.2067</td>\n",
       "      <td>42.7711</td>\n",
       "      <td>33.0325</td>\n",
       "      <td>34.5852</td>\n",
       "      <td>...</td>\n",
       "      <td>39.8251</td>\n",
       "      <td>36.8006</td>\n",
       "      <td>33.0467</td>\n",
       "      <td>35.3716</td>\n",
       "      <td>52.3633</td>\n",
       "      <td>42.8707</td>\n",
       "      <td>42.8806</td>\n",
       "      <td>43.4715</td>\n",
       "      <td>38.6105</td>\n",
       "      <td>41.5642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50.7812</td>\n",
       "      <td>47.7583</td>\n",
       "      <td>45.0808</td>\n",
       "      <td>38.0574</td>\n",
       "      <td>39.5245</td>\n",
       "      <td>37.3788</td>\n",
       "      <td>43.4920</td>\n",
       "      <td>47.8495</td>\n",
       "      <td>39.8416</td>\n",
       "      <td>39.3467</td>\n",
       "      <td>...</td>\n",
       "      <td>45.8703</td>\n",
       "      <td>44.1305</td>\n",
       "      <td>41.8964</td>\n",
       "      <td>42.8888</td>\n",
       "      <td>55.8803</td>\n",
       "      <td>43.9029</td>\n",
       "      <td>53.7123</td>\n",
       "      <td>49.9642</td>\n",
       "      <td>46.6670</td>\n",
       "      <td>50.3401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>54.6875</td>\n",
       "      <td>40.2770</td>\n",
       "      <td>37.2935</td>\n",
       "      <td>29.6998</td>\n",
       "      <td>30.8815</td>\n",
       "      <td>29.6544</td>\n",
       "      <td>35.6481</td>\n",
       "      <td>42.0118</td>\n",
       "      <td>35.8378</td>\n",
       "      <td>33.3848</td>\n",
       "      <td>...</td>\n",
       "      <td>39.9302</td>\n",
       "      <td>39.1320</td>\n",
       "      <td>38.2728</td>\n",
       "      <td>38.1070</td>\n",
       "      <td>45.9031</td>\n",
       "      <td>35.0073</td>\n",
       "      <td>52.2798</td>\n",
       "      <td>42.6238</td>\n",
       "      <td>42.3187</td>\n",
       "      <td>46.5558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>58.5938</td>\n",
       "      <td>29.7054</td>\n",
       "      <td>28.2113</td>\n",
       "      <td>18.7481</td>\n",
       "      <td>19.7947</td>\n",
       "      <td>19.3899</td>\n",
       "      <td>27.0491</td>\n",
       "      <td>32.9142</td>\n",
       "      <td>27.6715</td>\n",
       "      <td>24.2342</td>\n",
       "      <td>...</td>\n",
       "      <td>30.1080</td>\n",
       "      <td>29.6817</td>\n",
       "      <td>29.2025</td>\n",
       "      <td>28.4947</td>\n",
       "      <td>30.7703</td>\n",
       "      <td>25.1686</td>\n",
       "      <td>44.2137</td>\n",
       "      <td>30.1952</td>\n",
       "      <td>32.2482</td>\n",
       "      <td>35.7920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>62.5000</td>\n",
       "      <td>27.8484</td>\n",
       "      <td>28.9108</td>\n",
       "      <td>17.4641</td>\n",
       "      <td>18.5662</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>27.7724</td>\n",
       "      <td>31.2602</td>\n",
       "      <td>26.2626</td>\n",
       "      <td>22.8085</td>\n",
       "      <td>...</td>\n",
       "      <td>28.5257</td>\n",
       "      <td>28.4290</td>\n",
       "      <td>27.4537</td>\n",
       "      <td>26.3551</td>\n",
       "      <td>24.3644</td>\n",
       "      <td>24.4255</td>\n",
       "      <td>40.5826</td>\n",
       "      <td>25.8036</td>\n",
       "      <td>28.6333</td>\n",
       "      <td>30.0610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>66.4062</td>\n",
       "      <td>35.2774</td>\n",
       "      <td>38.1997</td>\n",
       "      <td>25.8704</td>\n",
       "      <td>27.5399</td>\n",
       "      <td>26.8358</td>\n",
       "      <td>36.3582</td>\n",
       "      <td>36.7867</td>\n",
       "      <td>32.3949</td>\n",
       "      <td>29.6220</td>\n",
       "      <td>...</td>\n",
       "      <td>36.6044</td>\n",
       "      <td>37.2835</td>\n",
       "      <td>35.9167</td>\n",
       "      <td>33.9725</td>\n",
       "      <td>30.8759</td>\n",
       "      <td>31.8548</td>\n",
       "      <td>44.2875</td>\n",
       "      <td>31.9227</td>\n",
       "      <td>34.7490</td>\n",
       "      <td>34.0319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>70.3125</td>\n",
       "      <td>41.7216</td>\n",
       "      <td>44.8413</td>\n",
       "      <td>32.8964</td>\n",
       "      <td>35.6618</td>\n",
       "      <td>34.1918</td>\n",
       "      <td>41.8751</td>\n",
       "      <td>39.8603</td>\n",
       "      <td>36.6848</td>\n",
       "      <td>35.2766</td>\n",
       "      <td>...</td>\n",
       "      <td>43.9096</td>\n",
       "      <td>45.5853</td>\n",
       "      <td>44.4238</td>\n",
       "      <td>41.3680</td>\n",
       "      <td>41.2876</td>\n",
       "      <td>37.2240</td>\n",
       "      <td>48.0081</td>\n",
       "      <td>38.6357</td>\n",
       "      <td>41.7653</td>\n",
       "      <td>40.7277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>74.2188</td>\n",
       "      <td>39.0086</td>\n",
       "      <td>41.1422</td>\n",
       "      <td>30.0883</td>\n",
       "      <td>33.9687</td>\n",
       "      <td>32.0526</td>\n",
       "      <td>37.3685</td>\n",
       "      <td>34.2636</td>\n",
       "      <td>32.0706</td>\n",
       "      <td>32.8132</td>\n",
       "      <td>...</td>\n",
       "      <td>41.3217</td>\n",
       "      <td>43.4583</td>\n",
       "      <td>42.8250</td>\n",
       "      <td>39.1924</td>\n",
       "      <td>45.1635</td>\n",
       "      <td>34.2447</td>\n",
       "      <td>45.0698</td>\n",
       "      <td>37.0833</td>\n",
       "      <td>40.6852</td>\n",
       "      <td>41.9102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time      FP1      AF7      AF3       F1       F3       F5       F7  \\\n",
       "10  39.0625  31.4110  32.0673  22.3352  25.0382  23.5137  35.1120  29.3931   \n",
       "11  42.9688  33.7772  34.1328  24.6102  27.0248  24.8361  35.6534  32.2594   \n",
       "12  46.8750  43.6999  42.6404  34.5724  36.4731  33.9406  42.2067  42.7711   \n",
       "13  50.7812  47.7583  45.0808  38.0574  39.5245  37.3788  43.4920  47.8495   \n",
       "14  54.6875  40.2770  37.2935  29.6998  30.8815  29.6544  35.6481  42.0118   \n",
       "15  58.5938  29.7054  28.2113  18.7481  19.7947  19.3899  27.0491  32.9142   \n",
       "16  62.5000  27.8484  28.9108  17.4641  18.5662  18.3560  27.7724  31.2602   \n",
       "17  66.4062  35.2774  38.1997  25.8704  27.5399  26.8358  36.3582  36.7867   \n",
       "18  70.3125  41.7216  44.8413  32.8964  35.6618  34.1918  41.8751  39.8603   \n",
       "19  74.2188  39.0086  41.1422  30.0883  33.9687  32.0526  37.3685  34.2636   \n",
       "\n",
       "        FT7      FC5  ...      CP4      CP2       P2       P4       P6  \\\n",
       "10  22.0631  23.7075  ...  27.3832  24.2128  19.9883  21.8572  40.9739   \n",
       "11  22.5779  25.0118  ...  28.8048  25.0436  20.5898  23.3805  42.6280   \n",
       "12  33.0325  34.5852  ...  39.8251  36.8006  33.0467  35.3716  52.3633   \n",
       "13  39.8416  39.3467  ...  45.8703  44.1305  41.8964  42.8888  55.8803   \n",
       "14  35.8378  33.3848  ...  39.9302  39.1320  38.2728  38.1070  45.9031   \n",
       "15  27.6715  24.2342  ...  30.1080  29.6817  29.2025  28.4947  30.7703   \n",
       "16  26.2626  22.8085  ...  28.5257  28.4290  27.4537  26.3551  24.3644   \n",
       "17  32.3949  29.6220  ...  36.6044  37.2835  35.9167  33.9725  30.8759   \n",
       "18  36.6848  35.2766  ...  43.9096  45.5853  44.4238  41.3680  41.2876   \n",
       "19  32.0706  32.8132  ...  41.3217  43.4583  42.8250  39.1924  45.1635   \n",
       "\n",
       "         P8      P10      PO8      PO4       O2  \n",
       "10  33.9711  26.3451  25.9169  24.9449  27.6925  \n",
       "11  35.6002  28.7708  30.2720  26.4836  29.2275  \n",
       "12  42.8707  42.8806  43.4715  38.6105  41.5642  \n",
       "13  43.9029  53.7123  49.9642  46.6670  50.3401  \n",
       "14  35.0073  52.2798  42.6238  42.3187  46.5558  \n",
       "15  25.1686  44.2137  30.1952  32.2482  35.7920  \n",
       "16  24.4255  40.5826  25.8036  28.6333  30.0610  \n",
       "17  31.8548  44.2875  31.9227  34.7490  34.0319  \n",
       "18  37.2240  48.0081  38.6357  41.7653  40.7277  \n",
       "19  34.2447  45.0698  37.0833  40.6852  41.9102  \n",
       "\n",
       "[10 rows x 65 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_data['lea']['data'][10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, labels, timestamps):\n",
    "    def to_true_label(label):\n",
    "        if label == 100:\n",
    "            raise Exception(\"Must skip labels with value 100!\")\n",
    "        if label == 195:\n",
    "            return 1\n",
    "        if label == 196:\n",
    "            return 2\n",
    "        return 0\n",
    "    \n",
    "    texts = []\n",
    "    x = []\n",
    "    y = []\n",
    "    start = timestamps[0]\n",
    "    for i, label in enumerate(labels):\n",
    "        if i == 0: continue\n",
    "        end = timestamps[i]\n",
    "        if label != 100:\n",
    "            x.append(data[int(start):int(end)])\n",
    "            y.append(to_true_label(label))\n",
    "        else:\n",
    "            texts.append((x,y))\n",
    "            x = []\n",
    "            y = []\n",
    "        start = timestamps[i]\n",
    "    texts.append((x,y))\n",
    "    if len(texts) != 3:\n",
    "        raise Exception(\"Texts must be 3, not \" + str(len(texts)))\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lea\n",
      "finn\n",
      "sarah\n",
      "aurora\n",
      "bjoern\n",
      "derek\n",
      "dimi\n",
      "ronan\n"
     ]
    }
   ],
   "source": [
    "X1 = []\n",
    "X2 = []\n",
    "X3 = []\n",
    "y1 = []\n",
    "y2 = []\n",
    "y3 = []\n",
    "for subj in subjects:\n",
    "    print(subj)\n",
    "    texts = split_data(subj_data[subj]['data'], subj_data[subj]['labels'], subj_data[subj]['timestamps'])\n",
    "    X1 += texts[0][0]\n",
    "    y1 += texts[0][1]\n",
    "    X2 += texts[1][0]\n",
    "    y2 += texts[1][1]\n",
    "    X3 += texts[2][0]\n",
    "    y3 += texts[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [X1, X2, X3]\n",
    "labels = [y1, y2, y3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bandwidths(data):\n",
    "    data = data.drop('Time', axis='columns').values.transpose()\n",
    "    # Define bandpass filter cutoff frequencies for each band\n",
    "    freq_ranges = {'Theta': (4, 8),\n",
    "                   'Alpha': (8, 12),\n",
    "                   'Beta': (12, 30),\n",
    "                   'Gamma': (30, 100)}\n",
    "    bandwidths = []\n",
    "    for i, channel_data in enumerate(data):\n",
    "        for j, (band_name, (low_freq, high_freq)) in enumerate(freq_ranges.items()):\n",
    "            # Apply bandpass filter\n",
    "            bandwidths.append(mne.filter.filter_data(channel_data, SAMPLING_RATE, low_freq, high_freq,verbose=False))\n",
    "    return bandwidths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/92 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [00:35<00:00,  2.60it/s]\n",
      "100%|██████████| 88/88 [00:32<00:00,  2.67it/s]\n",
      "100%|██████████| 56/56 [00:21<00:00,  2.61it/s]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for x in texts:\n",
    "    text = []\n",
    "    for i in tqdm(range(len(x))):\n",
    "        text.append(get_bandwidths(x[i]))\n",
    "    X.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outlier_ratio(values, m):\n",
    "    outliers = np.array(values)[abs(values - np.mean(values)) > m * np.std(values)]\n",
    "    return len(outliers)/len(values)\n",
    "\n",
    "def hjorth_mobility(signal):\n",
    "    diff1 = np.diff(signal)\n",
    "    var_signal = np.var(signal)\n",
    "    var_diff1 = np.var(diff1)\n",
    "    return np.sqrt(var_diff1 / var_signal)\n",
    "\n",
    "def hjorth_complexity(signal):\n",
    "    diff1 = np.diff(signal)\n",
    "    diff1_mobility = hjorth_mobility(diff1)\n",
    "    mobility = hjorth_mobility(signal)\n",
    "    return diff1_mobility / mobility\n",
    "\n",
    "def higuchi_fd(X, kmax=SAMPLING_RATE):\n",
    "    \"\"\"\n",
    "    Compute Higuchi Fractal Dimension of a time series X.\n",
    "    \n",
    "    Parameters:\n",
    "    X (array-like): The input time series data.\n",
    "    kmax (int): The maximum interval size.\n",
    "    \n",
    "    Returns:\n",
    "    float: The Higuchi Fractal Dimension.\n",
    "    \"\"\"\n",
    "    L = []\n",
    "    x = []\n",
    "    N = len(X)\n",
    "    for k in range(1, kmax + 1):\n",
    "        Lk = 0\n",
    "        for m in range(k):\n",
    "            # Empty list x\n",
    "            x = []\n",
    "            for i in range(1, int(np.floor((N - m) / k))):\n",
    "                x.append(X[m + i * k] - X[m + (i - 1) * k])\n",
    "            # Compute the length of the curve\n",
    "            Lk += np.sum(np.abs(x)) / ((N - 1) / ((N - m) / k) * k)\n",
    "        L.append(np.log(Lk / (m + 1)))\n",
    "    # Fit a line to the curve and return its slope\n",
    "    return np.polyfit(np.log(np.arange(1, kmax + 1)), L, 1)[0]\n",
    "\n",
    "def binarize_signal(signal):\n",
    "    \"\"\"\n",
    "    Binarizes a time series signal by taking the median value of the entire signal.\n",
    "    \n",
    "    Parameters:\n",
    "        signal (list or numpy array): The time series signal.\n",
    "        \n",
    "    Returns:\n",
    "        numpy array: The binarized signal.\n",
    "    \"\"\"\n",
    "    median_value = np.median(signal)\n",
    "    binarized_signal = np.where(signal >= median_value, 1, 0)\n",
    "    return binarized_signal\n",
    "\n",
    "\n",
    "def lempel_ziv_complexity(signal):\n",
    "    \"\"\"\n",
    "    Calculates the Lempel-Ziv Complexity (LZC) of a time series signal.\n",
    "    \n",
    "    Parameters:\n",
    "        signal (list or numpy array): The time series signal.\n",
    "        \n",
    "    Returns:\n",
    "        float: The Lempel-Ziv Complexity of the signal.\n",
    "    \"\"\"\n",
    "    binarized_signal = binarize_signal(signal)\n",
    "    unique_patterns = set()\n",
    "    lzc = 0\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(binarized_signal):\n",
    "        j = i + 1\n",
    "        while j <= len(binarized_signal):\n",
    "            pattern = tuple(binarized_signal[i:j])\n",
    "            if pattern not in unique_patterns:\n",
    "                unique_patterns.add(pattern)\n",
    "                lzc += 1\n",
    "                i = j - 1\n",
    "                break\n",
    "            j += 1\n",
    "        i += 1\n",
    "    \n",
    "    return lzc\n",
    "\n",
    "def extract_features(signal):\n",
    "    #signal /= np.mean(signal)\n",
    "    features = []\n",
    "\n",
    "    features.append(hjorth_mobility(signal))\n",
    "    features.append(hjorth_complexity(signal))\n",
    "    features.append(lempel_ziv_complexity(signal))\n",
    "    #features.append(higuchi_fd(signal, 100))\n",
    "\n",
    "    # Time-domain features\n",
    "    features.append(np.mean(signal))\n",
    "    features.append(np.var(signal))\n",
    "    features.append(stats.skew(signal))\n",
    "    features.append(stats.kurtosis(signal))\n",
    "    features.append(np.max(np.abs(signal)))  # Peak amplitude\n",
    "\n",
    "    # Frequency-domain features\n",
    "    f, psd = welch(signal)\n",
    "    features.append(np.mean(psd))  # Mean power spectral density\n",
    "    features.append(np.std(psd))\n",
    "    features.append(np.max(psd))\n",
    "    features.append(np.min(psd))\n",
    "    features.append(stats.entropy(psd))  # Spectral entropy\n",
    "    features.append(f[np.argmax(psd)])  # Spectral edge frequency\n",
    "\n",
    "    # Statistical features\n",
    "    features.append(np.median(signal))\n",
    "    features.append(stats.iqr(signal))  # Interquartile range\n",
    "    features.append(stats.kurtosis(np.diff(signal)))  # Kurtosis of first differences\n",
    "    features.append(stats.entropy(np.abs(signal)))  # Signal entropy\n",
    "    features.append(get_outlier_ratio(signal, 1.5))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [04:02<00:00,  2.64s/it]\n",
      "100%|██████████| 88/88 [04:32<00:00,  3.09s/it]\n",
      "100%|██████████| 56/56 [04:43<00:00,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for t in texts:\n",
    "    features = []\n",
    "    for i in tqdm(range(len(t))):\n",
    "        feature = []\n",
    "        for bw in t[i]:\n",
    "            feature += extract_features(bw)\n",
    "        features.append(feature)\n",
    "    X.append(features)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT 0:\n",
      "Train distribution: Counter({1: 66, 0: 65, 2: 13})\n",
      "Test distribution: Counter({0: 57, 1: 25, 2: 10})\n",
      "F1: 0.59, acc:  0.59, balanced_acc:  0.43\n",
      "RANDOM: F1: 0.29, acc:  0.29, balanced_acc:  0.21\n",
      "\n",
      "TEXT 1:\n",
      "Train distribution: Counter({0: 83, 1: 50, 2: 15})\n",
      "Test distribution: Counter({1: 41, 0: 39, 2: 8})\n",
      "F1: 0.55, acc:  0.55, balanced_acc:  0.44\n",
      "RANDOM: F1: 0.35, acc:  0.35, balanced_acc:  0.39\n",
      "\n",
      "TEXT 2:\n",
      "Train distribution: Counter({0: 96, 1: 66, 2: 18})\n",
      "Test distribution: Counter({0: 26, 1: 25, 2: 5})\n",
      "F1: 0.66, acc:  0.66, balanced_acc:  0.48\n",
      "RANDOM: F1: 0.32, acc:  0.32, balanced_acc:  0.34\n",
      "\n",
      "f1: 0.5977084509693205 0.047664836219963806\n",
      "acc: 0.5977084509693205 0.047664836219963806\n",
      "balanced_acc: 0.44863231405593407 0.023508797229436888\n",
      "rands_f1: 0.3223931865236213 0.024012429859267142\n",
      "rands_acc: 0.3223931865236213 0.024012429859267142\n",
      "balanced_rands_acc: 0.3223931865236213 0.07631153490684266\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Iterate over each fold\n",
    "f1s = []\n",
    "accs = []\n",
    "balanced_accs = []\n",
    "rands_f1 = []\n",
    "rands_acc = []\n",
    "balanced_rands_acc = []\n",
    "for i in range(3):\n",
    "    X_val = texts[i]\n",
    "    y_val = labels[i]\n",
    "    X_train = np.vstack([texts[j] for j in range(3) if j != i])\n",
    "    y_train = np.hstack([labels[j] for j in range(3) if j != i])\n",
    "    print(\"TEXT \" + str(i) + \":\")\n",
    "    print(\"Train distribution: \" + str(collections.Counter(y_train)))\n",
    "    print(\"Test distribution: \" + str(collections.Counter(y_val)))\n",
    "    scaler = StandardScaler()\n",
    "    imputer = KNNImputer(n_neighbors=50)\n",
    "    X_train = imputer.fit_transform(X_train)\n",
    "    X_val = imputer.transform(X_val)\n",
    "    scaler.fit_transform(X_train)\n",
    "    scaler.transform(X_val)\n",
    "\n",
    "    sample_weight = compute_sample_weight(class_weight=\"balanced\", y=y_train)\n",
    "    # Initialize SVM classifier\n",
    "    classifier = XGBClassifier(**{\n",
    "                    'objective': 'multi:softmax',\n",
    "                    'tree_method': 'auto',\n",
    "                    'random_state': SEED,\n",
    "                    'lambda': 44.95002293426431,\n",
    "                    'alpha': 0.004154520917950766,\n",
    "                    'colsample_bytree': 0.11602557907294059,\n",
    "                    'colsample_bylevel': 0.6792114962764053,\n",
    "                    'subsample': 0.9,\n",
    "                    'learning_rate': 0.13725312872605422,\n",
    "                    'n_estimators': 3099,\n",
    "                    'max_depth': 23,\n",
    "                    'min_child_weight': 1,\n",
    "                })\n",
    "    # Train the classifier on the training data\n",
    "    classifier.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "\n",
    "    # Make predictions on the validation data\n",
    "    y_pred = classifier.predict(X_val)\n",
    "\n",
    "    # Evaluate the classifier\n",
    "    rands = [random.randint(0,2) for _ in range(len(y_val))]\n",
    "    f1 = f1_score(y_val, y_pred, average='micro')\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    bal_acc = balanced_accuracy_score(y_val, y_pred)\n",
    "    f1s.append(f1)\n",
    "    balanced_accs.append(bal_acc)\n",
    "    accs.append(acc)\n",
    "    print(f\"F1: {f1:.2f}, acc: {acc: .2f}, balanced_acc: {bal_acc: .2f}\")\n",
    "    f1 = f1_score(y_val, rands, average='micro')\n",
    "    acc = accuracy_score(y_val, rands)\n",
    "    bal_acc = balanced_accuracy_score(y_val, rands)\n",
    "    rands_f1.append(f1)\n",
    "    rands_acc.append(acc)\n",
    "    balanced_rands_acc.append(bal_acc)\n",
    "    print(f\"RANDOM: F1: {f1:.2f}, acc: {acc: .2f}, balanced_acc: {bal_acc: .2f}\")\n",
    "    print()\n",
    "\n",
    "accs = list_to_nested_numpy(accs)\n",
    "f1s = list_to_nested_numpy(f1s)\n",
    "print(\"f1:\", np.mean(f1s), np.std(f1s))\n",
    "print(\"acc:\", np.mean(accs), np.std(accs))\n",
    "print(\"balanced_acc:\", np.mean(balanced_accs), np.std(balanced_accs))\n",
    "print(\"rands_f1:\", np.mean(rands_f1), np.std(rands_f1))\n",
    "print(\"rands_acc:\", np.mean(rands_acc), np.std(rands_acc))\n",
    "print(\"balanced_rands_acc:\", np.mean(rands_acc), np.std(balanced_rands_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                     ha=\"center\", va=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
